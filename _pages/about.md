---
permalink: /
title: "üëã Hi! I am Subhodip Panda"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

‚ÑπÔ∏è I am a third year Ph.D student at Representation Learning Lab of [ECE department, Indian Institute of Science (IISc), Bangalore](https://ece.iisc.ac.in/), advised by [Dr. Prathosh A.P](https://sites.google.com/view/prathosh/home). I am very fortunate to be mentored by [Dr. Ananda Theertha Suresh](http://theertha.info/) during current years of my Ph.D research.

‚ÑπÔ∏è Prior to beginning my doctoral studies, I worked as a research associate at [Oneirix Labs](https://www.oneirix.com/) in the field of Medical Imaging and AI.

‚ÑπÔ∏è I have completed my post-graduate studies in Statistics from [Indian Statistical Institute (ISI), Chennai](https://www.isichennai.res.in/) under the supervision of [Prof.Sudheesh Kumar K.](https://www.isichennai.res.in/~skkattu) and undergraduate studies in ECE from [Indian Institute of Engineering Science and Technology (IIEST),Shibpur](https://www.iiests.ac.in/).

<!-- ## ü§î Research Interests

My broader research interest lies in the domain of ***privacy and uncertainty aware learning algorithms***.  I am curious to know what each data point contributes in the learning process and I believe that privacy ([Diffential Privacy](https://en.wikipedia.org/wiki/Differential_privacy)) can help understand what these deep networks learn from each datapoint and if needed how we can unlearn ([Machine Unlearning](https://arxiv.org/abs/2209.02299)). Also, I am fascinated by distribution free uncertainty estimations for deep neural networks. Below are some of the topics that I am interested in:

- **üìå Privacy:** Machine Unlearning and Differential Privacy.
- **üìå Uncertainty:** Conformal Prediction and Calibration.
- **üìå Others:** Statistical Learning Theory and Information Theory. -->

## üîç Research Interests

My broader research focus lies in designing **privacy- and uncertainty-aware learning algorithms**. I am particularly curious about understanding:

- how each data point contributes to the learning process,
- and how one might *remove* that influence when needed.

I believe **[Differential Privacy](https://en.wikipedia.org/wiki/Differential_privacy)** offers a powerful lens into this question, and **[Machine Unlearning](https://arxiv.org/abs/2209.02299)** provides practical tools to achieve it. Additionally, I am interested in **distribution-free uncertainty estimation** for deep learning.

### üìö Topics of Interest

- üîê **Privacy**: Machine Unlearning, Differential Privacy  
- üéØ **Uncertainty**: Conformal Prediction, Calibration  
- üìò **Others**: Statistical Learning Theory, Information Theory  

---

> üì´ *Feel free to reach out to me via email if your interests align or you'd like to collaborate!*
